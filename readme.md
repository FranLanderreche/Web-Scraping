## Overview

We will be using the NYT API to download articles from the web.  Eventually we will be performing NLP and machine learning on the articles to do awesome things like document clustering, document filtering/classification, network analysis, and some indexing.  For this sprint we are just converened with getting some data.

## Goals
* HTTP and hypermedia (i.e. links)
* ReST
* MongoDB
* JSON APIs
* Beautiful Soup and Requests libraries
* HTML and CSS
* Data "Join" (i.e. get metadata from API and combine that with web scraping)
* Crawling vs. Parsing

## Reading

### HTTP

* [HTTP Request Life Cycle (StackOverflow)](http://stackoverflow.com/questions/4814514/http-request-life-cycle)
* [How does the internet work](http://docs.webplatform.org/wiki/concepts/internet_and_web/how_does_the_internet_work)

### ReST
* [Wikipedia](http://en.wikipedia.org/wiki/Representational_state_transfer)
* [Haters gonna HATEOAS](http://timelessrepo.com/haters-gonna-hateoas)

## Resources

* [Requests HTTP library](http://docs.python-requests.org/en/latest/)
* [Regular expression tester](http://pythex.org/)
* [Google Regex tutorial](https://developers.google.com/edu/python/regular-expressions)
* [Beautiful Soup (HTML parsing and searching)](http://www.crummy.com/software/BeautifulSoup/)
* [MongoDB Python driver](http://api.mongodb.org/python/current/tutorial.html)
* [Fielding's Dissertation](http://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm)
* [List of common HTTP status codes](http://www.smartlabsoftware.com/ref/http-status-codes.htm)
* [API client](http://www.getpostman.com/)
* [What is a "protocol"?](http://thomaslevine.com/!/street-sign-protocol)

## Assignment

See the [notebook](exercise.ipynb).
